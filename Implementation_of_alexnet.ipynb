{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWZvGMfV3Bbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):  # Default output classes set to 2 for binary classification\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # Convolutional Layers\n",
        "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0)  # First conv layer\n",
        "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2)  # Second conv layer\n",
        "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1)  # Third conv layer\n",
        "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)  # Fourth conv layer\n",
        "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)  # Fifth conv layer\n",
        "\n",
        "        # Pooling Layer\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)  # Flattened size after conv layers is 256 * 6 * 6\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "        # Batch normalization layers\n",
        "        self.batchnorm1 = nn.BatchNorm2d(96)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1: Conv -> BatchNorm -> ReLU -> MaxPool\n",
        "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Layer 2: Conv -> BatchNorm -> ReLU -> MaxPool\n",
        "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Layer 3: Conv -> ReLU\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        # Layer 4: Conv -> ReLU\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        # Layer 5: Conv -> ReLU -> MaxPool\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Flatten the output for fully connected layers\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "\n",
        "        # Fully Connected Layer 1 -> ReLU -> Dropout\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Fully Connected Layer 2 -> ReLU -> Dropout\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Fully Connected Layer 3 -> Softmax (for multi-class classification)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "# Initialize the model\n",
        "model = AlexNet(num_classes=10)  # Change num_classes to match your dataset\n",
        "\n",
        "# Print the model summary\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFswelpk3BcH",
        "outputId": "715e1bf5-90f6-460d-fbcd-5787bf002477"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (batchnorm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}